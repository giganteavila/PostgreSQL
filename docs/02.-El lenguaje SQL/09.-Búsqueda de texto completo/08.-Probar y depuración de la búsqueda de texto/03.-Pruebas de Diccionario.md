El  `ts_lexize`función facilita las pruebas de diccionario.



```
ts.lexize ( dictregdictionary,  tokentext) devoluciones text[]
```

 `ts_lexize`devuelve una serie de lexemes si la entrada  *`token`*es conocido por el diccionario, o un array vacío si el símbolo es conocido por el diccionario, pero es una palabra de parada, o  `NULL`si es una palabra desconocida.

Ejemplos:

```
SELECT ts.lexize('english-stem', 'estrellas');
 Ts-lexize
---------
 Estrella.

SELECT ts-lexize('english-stem', 'a');
 Ts-lexize
---------
 -
```

### Nota

El  `ts_lexize`función espera un solo *token*, no texto. Aquí hay un caso en el que esto puede ser confuso:

```
SELECT ts-lexize('thesaurus'astro', 'supernovae estrellas') es nulo;
 ?column?
---------
 t
```

El diccionario del tesuro  `thesaurus_astro`sabes la frase `supernovae stars`, pero  `ts_lexize`fracasa ya que no analiza el texto de entrada sino que lo trata como una sola ficha. Uso  `plainto_tsquery`o o  `to_tsvector`para probar los diccionarios del tesuro, por ejemplo:

```
SELECT plainto-tsquery('supernovae estrellas');
 plainto-tsquery
----------------
 'n'
```